{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laser Machine Listener\n",
    "\n",
    "The following code implements machine learning with Keras (and TensorFlow as a backend) to classify sounds emitted by a laser machine during processing such as cutting and marking. The assumed states are as follows. As learning data, prepare folders as many as the number of states in the **data** folder, and place one or more sound files corresponding to each state in each folder.\n",
    "\n",
    "- Background\n",
    "- Cutting (in focus)\n",
    "- Cutting (not in focus)\n",
    "- Marking\n",
    "- Waiting\n",
    "- Sleeping\n",
    "\n",
    "以下のコードは、レーザー加工機がカットやマーキングなどの加工中に発する音を分類するための機械学習をKeras（とバックエンドとしてのTensorFlow）で実装したものです。想定している状態は以下の通りです。学習用のデータとして、**data**フォルダの中に状態の数だけフォルダを用意し、それぞれのフォルダの中にそれぞれの状態に対応する1つまたはそれ以上の音声ファイルを配置してください。\n",
    "\n",
    "- 背景音\n",
    "- カット中（焦点が合っている）\n",
    "- カット中（焦点が合っていない）\n",
    "- マーキング中\n",
    "- 待機中\n",
    "- スリープ中\n",
    "\n",
    "| State | Laser Machine | Dust collector | Ventilator |\n",
    "| --: | :-- | :-- | :-- |\n",
    "| Background | OFF | OFF | OFF |\n",
    "| Sleeping | OFF | OFF | ON |\n",
    "| Waiting | ON | ON | ON |\n",
    "| Cutting (in focus) | ON | ON | ON |\n",
    "| Cutting (not in focus) | ON | ON | ON |\n",
    "| Marking | ON | ON | ON |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we initialise an array for containing state names and a matrix for storing voice data and correct labels. Next, read sound files matching the pattern of the path for 30 seconds in order, normalize, obtain STFT, and register together with the same number of correct answer labels.\n",
    "\n",
    "まず、状態名を収めるための配列と、音声データと正解ラベルを収めるための行列を初期化する。次に、パスのパターンに合致する音声ファイルを順に30秒間ずつ読み込み、正規化したのちにSTFTを求め、同数の正解ラベルと共に登録する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import librosa\n",
    "\n",
    "SAMPLING_RATE = 16000\n",
    "FFT_SIZE = 256\n",
    "STFT_MATRIX_SIZE = 1 + FFT_SIZE // 2\n",
    "\n",
    "state_names = []\n",
    "data = np.empty((0, STFT_MATRIX_SIZE), dtype=np.float32)\n",
    "index = np.empty(0, dtype=np.int32)\n",
    "\n",
    "for path_name in sorted(glob.glob('data/*/*.wav')):\n",
    "    state_name = path_name.split('/')[1]\n",
    "\n",
    "    if state_name not in state_names:\n",
    "        state_names.append(state_name)\n",
    "\n",
    "    audio, sr = librosa.load(path_name, sr=SAMPLING_RATE, duration=30)\n",
    "    print('{}: {} ({} Hz) '.format(state_name, path_name, sr))\n",
    "    d = np.abs(librosa.stft(librosa.util.normalize(audio),\n",
    "                            n_fft=FFT_SIZE, window='hamming'))\n",
    "    data = np.vstack((data, d.transpose()))\n",
    "    index = np.hstack([index, [state_names.index(state_name)] * d.shape[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check what kind of difference is seen when viewing each state on the frequency axis, we calculate the average of STFT for each state and draw with matplotlib.\n",
    "\n",
    "それぞれの状態を周波数軸で見たときにどのような違いがあるのかを確認するため、状態ごとにSTFTの平均を求め、matplotlibを用いて描画します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_states = len(state_names)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5 * n_states))\n",
    "\n",
    "for i, state_name in enumerate(state_names):\n",
    "    plt.subplot(n_states, 1, 1 + i)\n",
    "    plt.plot(librosa.fft_frequencies(sr=SAMPLING_RATE, n_fft=FFT_SIZE),\n",
    "             np.mean(data[np.where(index == i)], axis=0))\n",
    "    plt.title(state_name)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data was prepared as above. First, define a model of the neural network with Keras, and divide the data and the correct index into 80% for learning and the remaining 20% for verification. Next, Select Adam as an optimisation method, set the number of epochs to 20, and set an early stopping when there is no change in the correct answer rate, and execute learning. When using the files bundled as samples, the correct answer rate is about 95%. If you do not get the proper answer rate for the examples you prepared, try tuning parameters such as `N_MID_UNITS` and `BATCH_SIZE`.\n",
    "\n",
    "以上でデータが用意できました。まず、Kerasでニューラルネットワークのモデルを定義し、データと正解インデックスをのうち、8割を学習用、残りの2割を検証用に分けます。次に、最適化手法としてAdamを選択、エポック数は20に設定し、正解率に変化がなくなったら早期に終了するように設定した上で学習を実行します。サンプルとして同梱しているファイルを用いた場合、正解率は約95%程度になります。もし、自分で用意したサンプルに対する正解率が上がらない場合には、`N_MID_UNITS`や`BATCH_SIZE`などのパラメータをチューニングしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "N_MID_UNITS = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(N_MID_UNITS, activation='sigmoid', input_dim=STFT_MATRIX_SIZE))\n",
    "model.add(Dense(N_MID_UNITS // 2, activation='sigmoid'))\n",
    "model.add(Dense(n_states, activation='softmax'))\n",
    "model.compile(Adam(lr=0.01),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "index_cat = keras.utils.to_categorical(index)\n",
    "data_train, data_test, index_train, index_test = train_test_split(data, index_cat, test_size=0.2)\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "es_callback = EarlyStopping(monitor='val_acc',\n",
    "                            patience=2,\n",
    "                            verbose=True,\n",
    "                            mode='auto')\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "model.fit(data_train, index_train, epochs=20, batch_size=BATCH_SIZE,\n",
    "          validation_split=0.2, callbacks=[es_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When learning is over, test with the data and correct answer index that have been separated for verification.\n",
    "\n",
    "学習が終わったら、検証のために分離しておいたデータと正解インデックスを用いて確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(data_test, index_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, save the array containing the state name and the learned model as separate files.\n",
    "\n",
    "最後に、状態の名前を収めた配列と学習済みのモデルを個別のファイルとして保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('state_names.json', 'w') as file_to_save:\n",
    "    json.dump(state_names, file_to_save)\n",
    "\n",
    "model.save('laser_machine_listener.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
